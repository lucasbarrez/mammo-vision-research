"""
Script de test de la structure VLM (sans ex√©cution CLIP)
V√©rifie que tous les modules sont importables et coh√©rents
"""

import sys
import os

# Ajouter les chemins
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../CNN/breakhis_8classes_classification'))

print("="*70)
print("üß™ TEST DE LA STRUCTURE VLM ZERO-SHOT")
print("="*70)

# Test 1: Configuration
print("\n[1/6] Test de la configuration...")
try:
    # Import direct
    vlm_config_module = __import__('config.config', fromlist=['VLMConfig'])
    VLMConfig = vlm_config_module.VLMConfig
    
    # Import CNN config depuis le chemin absolu
    cnn_config_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../CNN/breakhis_8classes_classification'))
    if cnn_config_path not in sys.path:
        sys.path.append(cnn_config_path)
    
    import importlib.util
    spec = importlib.util.spec_from_file_location("cnn_config", os.path.join(cnn_config_path, "config/config.py"))
    cnn_config_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(cnn_config_module)
    CNNConfig = cnn_config_module.Config
    
    # V√©rifier la coh√©rence
    assert VLMConfig.LABEL_TO_INT == CNNConfig.LABEL_TO_INT, "LABEL_TO_INT diff√©rent!"
    assert VLMConfig.MALIGNANT_CLASSES == CNNConfig.MALIGNANT_CLASSES, "MALIGNANT_CLASSES diff√©rent!"
    assert VLMConfig.NUM_CLASSES == CNNConfig.NUM_CLASSES, "NUM_CLASSES diff√©rent!"
    
    print(f"  ‚úÖ Configuration VLM import√©e")
    print(f"     - NUM_CLASSES: {VLMConfig.NUM_CLASSES}")
    print(f"     - Mod√®le CLIP: {VLMConfig.CLIP_MODEL_NAME}")
    print(f"     - Strat√©gie: {VLMConfig.PROMPT_STRATEGY}")
    print(f"  ‚úÖ Coh√©rence avec CNN v√©rifi√©e")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# Test 2: Prompts
print("\n[2/6] Test du g√©n√©rateur de prompts...")
try:
    from prompts.prompt_strategies import PromptGenerator
    
    strategies = ['simple', 'descriptive', 'medical', 'contextual', 'ensemble']
    for strategy in strategies:
        gen = PromptGenerator(strategy=strategy)
        prompts = gen.generate_all_class_prompts()
        assert len(prompts) == 8, f"Devrait avoir 8 classes, a {len(prompts)}"
    
    print(f"  ‚úÖ 5 strat√©gies de prompting fonctionnelles")
    print(f"     - Strategies: {', '.join(strategies)}")
    
    # Afficher un exemple
    gen = PromptGenerator(strategy='medical')
    dc_prompts = gen.generate_prompts_for_class('Ductal Carcinoma')
    print(f"     - Exemple (medical): \"{dc_prompts[0][:60]}...\"")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# Test 3: Structure de dataset (sans donn√©es r√©elles)
print("\n[3/6] Test de la structure dataset...")
try:
    # On ne peut pas vraiment tester sans les donn√©es, mais on v√©rifie les imports
    import pandas as pd
    from PIL import Image
    
    # Simuler un petit DataFrame
    test_df = pd.DataFrame({
        'path': ['test1.png', 'test2.png'],
        'label': ['Adenosis', 'Ductal Carcinoma'],
        'is_malignant': [False, True]
    })
    
    print(f"  ‚úÖ D√©pendances dataset OK (Pandas, PIL)")
    print(f"     - Peut cr√©er des DataFrames")
    print(f"     - PIL disponible pour charger les images")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# Test 4: √âvaluation (structure uniquement)
print("\n[4/6] Test de la structure d'√©valuation...")
try:
    import numpy as np
    from sklearn.metrics import accuracy_score
    
    # Test avec des donn√©es fictives
    y_true = np.array([0, 1, 2, 3, 4, 5, 6, 7])
    y_pred = np.array([0, 1, 2, 3, 4, 5, 6, 7])
    acc = accuracy_score(y_true, y_pred)
    
    print(f"  ‚úÖ Modules d'√©valuation OK")
    print(f"     - NumPy, scikit-learn disponibles")
    print(f"     - Test accuracy: {acc:.2f}")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# Test 5: Visualisation (structure uniquement)
print("\n[5/6] Test de la structure de visualisation...")
try:
    import matplotlib
    matplotlib.use('Agg')  # Backend sans affichage
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    print(f"  ‚úÖ Modules de visualisation OK")
    print(f"     - Matplotlib version: {matplotlib.__version__}")
    print(f"     - Seaborn disponible")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# Test 6: V√©rification des fichiers
print("\n[6/6] V√©rification de la structure des fichiers...")
try:
    required_files = [
        'main.py',
        'config/config.py',
        'data/dataset_loader.py',
        'models/clip_model.py',
        'models/cplip_model.py',
        'prompts/prompt_strategies.py',
        'evaluation/metrics.py',
        'evaluation/visualization.py',
        'requirements.txt',
        'README.md'
    ]
    
    base_dir = os.path.dirname(__file__)
    missing = []
    for f in required_files:
        full_path = os.path.join(base_dir, f)
        if not os.path.exists(full_path):
            missing.append(f)
    
    if missing:
        print(f"  ‚ùå Fichiers manquants: {missing}")
    else:
        print(f"  ‚úÖ Tous les fichiers pr√©sents ({len(required_files)} fichiers)")
        print(f"     - Structure compl√®te et coh√©rente")
except Exception as e:
    print(f"  ‚ùå Erreur: {e}")
    sys.exit(1)

# R√©sum√©
print("\n" + "="*70)
print("‚úÖ TOUS LES TESTS PASS√âS!")
print("="*70)
print("""
üìã R√©sum√©:
  - Configuration coh√©rente avec le CNN
  - 5 strat√©gies de prompting fonctionnelles
  - Structure de dataset pr√™te (n√©cessite donn√©es + PyTorch pour run complet)
  - Modules d'√©valuation et visualisation OK
  - Tous les fichiers pr√©sents

‚ö†Ô∏è  Pour un test complet avec CLIP:
  1. Installer/r√©parer PyTorch: pip install torch torchvision
  2. Installer OpenCLIP: pip install open-clip-torch
  3. S'assurer que le dataset BreakHis est disponible
  4. Ex√©cuter: python main.py

üéØ La structure est pr√™te √† √™tre commit√©e!
""")
