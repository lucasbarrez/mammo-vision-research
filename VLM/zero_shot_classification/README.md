# Classification Zero-Shot avec CLIP/CPLIP

## ğŸ“‹ Description

Ce module implÃ©mente la classification **zero-shot** d'images histopathologiques du dataset BreakHis en utilisant des modÃ¨les Vision-Langage (CLIP/CPLIP).

**CohÃ©rence avec le projet CNN**: Ce code rÃ©utilise les modules existants du CNN (`data/preprocessing.py`, `config/config.py`, mÃ©triques) pour assurer la cohÃ©rence des rÃ©sultats.

## ğŸ—ï¸ Architecture

```
VLM/zero_shot_classification/
â”œâ”€â”€ main.py                          # Script principal (style CNN)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                    # Configuration VLM
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset_loader.py            # Chargeur rÃ©utilisant le code CNN
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ clip_model.py                # Wrapper CLIP (OpenCLIP)
â”‚   â””â”€â”€ cplip_model.py               # Placeholder pour CPLIP
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_strategies.py         # 5 stratÃ©gies de prompting
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py                   # MÃ©triques (rÃ©utilise recall_malignant du CNN)
â”‚   â””â”€â”€ visualization.py             # Graphiques
â”œâ”€â”€ logs/                            # Logs horodatÃ©s (comme CNN)
â””â”€â”€ results/                         # RÃ©sultats JSON + visualisations
```

## ğŸš€ Installation

```bash
# DÃ©pendances PyTorch + CLIP
pip install torch torchvision
pip install open-clip-torch
pip install pillow numpy pandas scikit-learn matplotlib seaborn tqdm
```

## ğŸ“Š Utilisation

### Ã‰valuation basique

```bash
cd VLM/zero_shot_classification
python main.py
```

Le script va:
1. âœ… Charger les donnÃ©es (rÃ©utilise le `prepare_breakhis_subset` du CNN)
2. âœ… Charger CLIP (ViT-B/32 par dÃ©faut)
3. âœ… GÃ©nÃ©rer les prompts (stratÃ©gie "medical" par dÃ©faut)
4. âœ… Ã‰valuer en zero-shot sur le test set
5. âœ… Sauvegarder les rÃ©sultats dans `logs/` et `results/`

### Configuration

Modifier [config/config.py](config/config.py):

```python
VLMConfig.CLIP_MODEL_NAME = "ViT-L/14"  # Changer le modÃ¨le CLIP
VLMConfig.PROMPT_STRATEGY = "ensemble"  # Changer la stratÃ©gie
VLMConfig.DEVICE = "mps"                # Pour Mac M1/M2
```

## ğŸ¯ StratÃ©gies de Prompting

| StratÃ©gie | Description | Exemple |
|-----------|-------------|---------|
| `simple` | Prompt minimal | "a histopathological image of Ductal Carcinoma" |
| `descriptive` | Contexte histologique | "microscopy image showing Ductal Carcinoma" |
| `medical` | Descriptions cliniques | "malignant breast cancer originating in milk ducts" |
| `contextual` | Contexte diagnostique | "breast cancer histopathology: Ductal Carcinoma" |
| `ensemble` | Combinaison de toutes | Moyenne de tous les prompts |

## ğŸ“ˆ MÃ©triques

**CohÃ©rent avec le CNN**: Utilise les mÃªmes mÃ©triques, notamment `recall_malignant` (critique pour le cancer).

- âœ… Accuracy globale
- âœ… Precision / Recall / F1-Score (macro + par classe)
- âœ… **Recall sur cancers malins** (mÃ©trique clÃ© du projet)
- âœ… Matrice de confusion
- âœ… Comparaison des stratÃ©gies de prompting

## ğŸ”¬ ModÃ¨les CLIP Disponibles

| ModÃ¨le | Params | RÃ©solution | Performance attendue |
|--------|--------|------------|----------------------|
| ViT-B/32 | 87M | 224x224 | Baseline rapide |
| ViT-B/16 | 87M | 224x224 | Meilleur que B/32 |
| ViT-L/14 | 304M | 224x224 | Meilleure qualitÃ© |
| RN50 | 102M | 224x224 | CNN-based |
| RN101 | 119M | 224x224 | CNN-based, plus profond |

## ğŸ†š Comparaison avec le CNN

| Approche | EntraÃ®nement | AdaptÃ© au domaine | CoÃ»t |
|----------|--------------|-------------------|------|
| **CNN (EfficientNet)** | âœ… SupervisÃ© | âœ… Fine-tunÃ© | High compute |
| **CLIP (zero-shot)** | âŒ Aucun | âŒ GÃ©nÃ©raliste | Low compute |
| **CPLIP (zero-shot)** | âŒ Aucun | ğŸŸ¡ PrÃ©-entraÃ®nÃ© mÃ©dical | Low compute |

**HypothÃ¨se**: Le CNN devrait surpasser CLIP en zero-shot, mais CLIP avec prompting intelligent peut Ãªtre compÃ©titif.

## ğŸ“ Format des Logs

Identique au CNN: `logs/log_YYYYMMDD_HHMMSS.txt`

```
======================================================================
  CLASSIFICATION ZERO-SHOT - MODÃˆLES VISION-LANGAGE (CLIP/CPLIP)
======================================================================

======================================================================
Ã‰TAPE 1: PRÃ‰PARATION DES DONNÃ‰ES
======================================================================
ğŸ—ï¸ CrÃ©ation du subset BreakHis Ã  200x...
...
```

## ğŸ¯ TODO / Roadmap

- [ ] ImplÃ©menter CPLIP (attente du modÃ¨le)
- [ ] Tester toutes les stratÃ©gies de prompting
- [ ] Comparer les variantes CLIP (ViT vs ResNet)
- [ ] Analyser les erreurs (cancers manquÃ©s)
- [ ] Visualisation t-SNE des embeddings
- [ ] Prompt engineering avancÃ© (CoOp, CoCoOp)

## ğŸ‘¥ Ã‰quipe

- **Alexandre** (toi): CLIP/CPLIP zero-shot + prompting
- **Lina + Lamia**: CNN multiclasse (EfficientNet)
- **Lucas**: DINO + clustering

## ğŸ“š RÃ©fÃ©rences

- CLIP: [OpenAI paper](https://arxiv.org/abs/2103.00020)
- CPLIP: [Microsoft CPLIP](https://github.com/microsoft/CPLIP)
- BreakHis: [Dataset paper](https://doi.org/10.1109/TBME.2015.2496264)
