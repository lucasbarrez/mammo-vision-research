ANALYSE COMPARATIVE

Classification d'Images Histopathologiques
Dataset BreakHis - 8 Classes


Comparaison des Architectures:
CNN ¬∑ Vision Transformer ¬∑ Hybride CNN+ViT


Auteur: Lamia Ladraa
Date: 18 Janvier 2026
Plateforme: Google Colab (Tesla T4 GPU)


# Table des Mati√®res

  1. R√©sum√© Ex√©cutif
  2. Contexte et Objectifs
  3. Dataset BreakHis
  4. M√©triques de Performance
  5. Analyse par Mod√®le
  5.1 EfficientNet (CNN)
  5.2 Vision Transformer (ViT)
  5.3 Mod√®le Hybride CNN+ViT
  6. Comparaison D√©taill√©e
  6.1 Performance Globale
  6.2 Analyse par Classe
  6.3 Matrices de Confusion
  7. Insights et D√©couvertes
  8. Recommandations
  9. Conclusions
  10. Annexes

# 1. R√©sum√© Ex√©cutif

Cette √©tude compare trois architectures de deep learning pour la classification d'images histopathologiques de cancer du sein (dataset BreakHis, 8 classes). Les mod√®les √©valu√©s sont : EfficientNetB0 (CNN pur), Vision Transformer (ViT from scratch), et un mod√®le Hybride fusionnant CNN et ViT.

## R√©sultats Principaux

* Le recall malin du ViT est trompeur : il ne d√©tecte qu'un seul type de cancer (Ductal Carcinoma) et ignore compl√®tement 3 autres types de cancer.

## Recommandation Clinique

Le mod√®le Hybride CNN+ViT est recommand√© pour l'assistance au diagnostic avec un recall malignant de 75.57%, d√©tectant 99 cancers sur 131. Il surpasse significativement les approches pures CNN ou ViT, particuli√®rement sur les classes difficiles comme le Mucinous Carcinoma (35% vs 7% pour le CNN).


# 2. Contexte et Objectifs

## Contexte M√©dical

Le cancer du sein pr√©sente plusieurs sous-types histopathologiques avec des caract√©ristiques visuelles distinctes. L'identification pr√©cise du sous-type est cruciale pour le pronostic et le traitement. L'analyse histopathologique traditionnelle repose sur l'expertise humaine, ce qui peut √™tre chronophage et sujet √† variabilit√© inter-observateur.

## Objectifs de l'√âtude

- √âvaluer trois architectures de deep learning pour la classification automatique
- Comparer les approches CNN pures, Transformer pures, et hybrides
- Identifier les forces et faiblesses de chaque architecture
- Recommander le mod√®le optimal pour assistance au diagnostic clinique
## M√©thodologie

Trois mod√®les ont √©t√© entra√Æn√©s sur le m√™me dataset BreakHis avec des configurations optimis√©es pour chaque architecture. L'√©valuation s'est concentr√©e sur le recall des classes malignes (cancers), crit√®re prioritaire en contexte m√©dical pour minimiser les faux n√©gatifs.


# 3. Dataset BreakHis

Le dataset BreakHis (Breast Cancer Histopathological Database) contient des images microscopiques de biopsies mammaires √† diff√©rents facteurs de grossissement. Pour cette √©tude, nous avons utilis√© les images √† 200√ó de grossissement.

## Caract√©ristiques du Dataset

## Classes

- Classes B√©nignes:
- Adenosis (111 images) - Prolif√©ration de glandes
- Fibroadenoma (264 images) - Tumeur b√©nigne commune
- Tubular Adenoma (140 images) - Ad√©nome tubulaire
- Phyllodes Tumor (108 images) - Tumeur fibreuse rare
- Classes Malignes (Cancers):
- Ductal Carcinoma (896 images) - Type le plus fr√©quent (69%)
- Lobular Carcinoma (163 images) - 2√®me type le plus fr√©quent
- Mucinous Carcinoma (196 images) - Carcinome mucineux
- Papillary Carcinoma (135 images) - Structure papillaire
## D√©s√©quilibre des Classes

Le dataset pr√©sente un d√©s√©quilibre significatif : le Ductal Carcinoma repr√©sente 44.5% de toutes les images, cr√©ant un biais vers cette classe majoritaire. Ce d√©s√©quilibre constitue un d√©fi majeur pour l'apprentissage √©quilibr√© des 8 classes.


# 4. M√©triques de Performance

## Accuracy (Exactitude Globale)

Pourcentage de pr√©dictions correctes sur l'ensemble du test set. M√©trique simple mais peut √™tre trompeuse en cas de classes d√©s√©quilibr√©es.

Formule : (Vrais Positifs + Vrais N√©gatifs) / Total

## Recall (Sensibilit√©)

Capacit√© du mod√®le √† d√©tecter les cas positifs. M√©trique CRITIQUE en m√©decine car mesure la proportion de vrais cas d√©tect√©s. Un recall faible signifie beaucoup de faux n√©gatifs (cas manqu√©s).

Formule : Vrais Positifs / (Vrais Positifs + Faux N√©gatifs)

## Precision (Pr√©cision)

Proportion de pr√©dictions positives qui sont correctes. Une precision √©lev√©e signifie peu de faux positifs.

Formule : Vrais Positifs / (Vrais Positifs + Faux Positifs)

## Recall Malignant

M√âTRIQUE PRINCIPALE pour l'√©valuation clinique. Mesure la capacit√© √† d√©tecter les cancers (classes malignes). Un recall malignant √©lev√© est prioritaire car manquer un cancer a des cons√©quences graves.

## Macro Recall

Moyenne non pond√©r√©e des recalls de toutes les classes. Mesure la performance √©quilibr√©e sur toutes les classes, ind√©pendamment de leur fr√©quence.

## Entropie des Pr√©dictions

Mesure l'√©quilibre de la distribution des pr√©dictions (max = 3.0 pour 8 classes). Une entropie faible indique que le mod√®le pr√©dit principalement quelques classes, ce qui peut signaler un probl√®me d'apprentissage.


# 5. Analyse par Mod√®le

## 5.1 EfficientNet (CNN Pur)

### Architecture

EfficientNetB0 est un CNN compact et efficace, pr√©-entra√Æn√© sur ImageNet. L'architecture utilise des compound scaling et des mobile inverted bottleneck convolutions (MBConv) pour optimiser le rapport performance/param√®tres.

### R√©sultats

### Forces

- ‚úÖ D√©tecte TOUTES les 8 classes (aucune recall = 0%)
- ‚úÖ Distribution √©quilibr√©e des pr√©dictions (entropie 2.73/3.0)
- ‚úÖ Excellent sur Phyllodes Tumor (80% recall)
- ‚úÖ Bon sur Papillary Carcinoma (68.4% recall)
- ‚úÖ Architecture √©prouv√©e et stable
- ‚úÖ Rapide √† entra√Æner (~50 min)
### Faiblesses

- ‚ùå Mucinous Carcinoma : recall catastrophique (6.7% - 1/15 d√©tect√©)
- ‚ùå Tubular Adenoma : recall faible (33.3%)
- ‚ùå Performances globales modestes (55%)
- ‚ö†Ô∏è Confusion Ductal ‚Üî Papillary : 13 erreurs crois√©es
- ‚ö†Ô∏è 5 Mucinous confondus avec Adenosis (cancer ‚Üí b√©nin, GRAVE)
### Verdict

EfficientNet constitue une baseline solide et fiable. Bien que ses performances absolues soient modestes (55%), il pr√©sente l'avantage crucial de d√©tecter toutes les classes avec un comportement √©quilibr√© et pr√©visible. Son principal probl√®me est la classe Mucinous Carcinoma, qu'il confond souvent avec des tumeurs b√©nignes.


## 5.2 Vision Transformer (ViT from scratch)

### Architecture

Vision Transformer impl√©ment√© from scratch (sans pr√©-entra√Ænement) bas√© sur l'architecture originale 'An Image is Worth 16x16 Words'. Utilise des m√©canismes d'attention multi-t√™tes pour capturer les relations globales dans l'image.

### R√©sultats

### Le Probl√®me CRITIQUE

Le ViT pr√©sente un effondrement catastrophique : il ne pr√©dit que 2 classes sur 8, ignorant compl√®tement 6 classes dont 3 types de cancer.

Distribution des pr√©dictions ViT:

‚Ä¢ Ductal Carcinoma : 129/202 (63.9%) ‚Üê Pr√©diction dominante

‚Ä¢ Tubular Adenoma : 62/202 (30.7%) ‚Üê 2√®me pr√©diction

‚Ä¢ Lobular Carcinoma : 11/202 (5.4%)

‚Ä¢ 5 autres classes : 0/202 (0.0%) ‚Üê JAMAIS PR√âDITES

### Classes Jamais D√©tect√©es (Recall = 0%)

- ‚ùå Adenosis (0/8 d√©tect√©s)
- ‚ùå Fibroadenoma (0/37 d√©tect√©s)
- ‚ùå Phyllodes Tumor (0/13 d√©tect√©s)
- ‚ùå Lobular Carcinoma (0/15 d√©tect√©s) ‚Üê CANCER!
- ‚ùå Mucinous Carcinoma (0/17 d√©tect√©s) ‚Üê CANCER!
- ‚ùå Papillary Carcinoma (0/12 d√©tect√©s) ‚Üê CANCER!
### Pourquoi le Recall Malignant est Trompeur

Le ViT affiche un recall malignant de 60.31% (79/131 cancers d√©tect√©s), ce qui pourrait sembler acceptable. MAIS :

‚Ä¢ Les 79 cancers d√©tect√©s sont TOUS des Ductal Carcinoma

‚Ä¢ 0% de d√©tection pour Lobular (15 cas manqu√©s)

‚Ä¢ 0% de d√©tection pour Mucinous (17 cas manqu√©s)

‚Ä¢ 0% de d√©tection pour Papillary (12 cas manqu√©s)

‚Ä¢ Le recall √©lev√© vient uniquement de la dominance du Ductal dans le dataset

‚ö†Ô∏è En pratique : le ViT manque 44 cancers non-Ductal sur 44 (100%). C'est INACCEPTABLE cliniquement.

### Causes de l'√âchec

  1. Absence de pr√©-entra√Ænement : ViT n√©cessite ImageNet-21k (14M images)
  2. Dataset trop petit : 1610 images insuffisantes pour ViT from scratch
  3. D√©s√©quilibre des classes : collapse vers la classe majoritaire (Ductal)
  4. Convergence √©chou√©e : le mod√®le n'a jamais vraiment appris
  5. Learning rate inadapt√© : trop conservateur pour from scratch
### Verdict

Le Vision Transformer from scratch est un √âCHEC TOTAL et DANGEREUX pour cette application. Il ignore 3 types de cancer sur 4 et pr√©sente un comportement compl√®tement d√©s√©quilibr√©. Ce mod√®le est INUTILISABLE en production clinique. Un ViT pr√©-entra√Æn√© (ImageNet-21k) aurait probablement donn√© des r√©sultats significativement meilleurs.


## 5.3 Mod√®le Hybride CNN+ViT

### Architecture

Architecture innovante fusionnant les forces du CNN (features locales) et du ViT (contexte global). Le mod√®le traite l'image en parall√®le avec deux branches puis fusionne les repr√©sentations.

Branch 1 : CNN (Features Locales)

‚Ä¢ Backbone : EfficientNetB0 pr√©-entra√Æn√© (frozen)

‚Ä¢ Features : 1280 dimensions

‚Ä¢ R√¥le : D√©tection de textures, patterns, structures microscopiques

Branch 2 : ViT (Contexte Global)

‚Ä¢ Patches : 16√ó16 (196 patches au total)

‚Ä¢ Transformer blocks : 3 (r√©duit vs ViT pur)

‚Ä¢ Attention heads : 6 par block

‚Ä¢ Projection dim : 384 dimensions

‚Ä¢ Features : 384 dimensions

‚Ä¢ R√¥le : Relations spatiales, organisation cellulaire globale

Fusion et Classification

‚Ä¢ Concatenation : [1280D CNN + 384D ViT] = 1664D

‚Ä¢ Dense(512) + BatchNorm + Dropout(0.3)

‚Ä¢ Dense(256) + BatchNorm + Dropout(0.15)

‚Ä¢ Dense(8) + Softmax

‚Ä¢ Param√®tres totaux : ~8.7M

### R√©sultats

### Forces

- ‚úÖ Meilleure accuracy globale (64.36%)
- ‚úÖ Meilleur recall malignant (75.57%) - PRIORIT√â CLINIQUE
- ‚úÖ D√©tecte toutes les 8 classes (8/8)
- ‚úÖ Excellent sur Ductal Carcinoma (87.4% recall)
- ‚úÖ Tr√®s bon sur Adenosis (87.5% recall, +29% vs CNN)
- ‚úÖ R√©sout le probl√®me Mucinous (35.3% recall vs 6.7% CNN) - am√©lioration √ó5
- ‚úÖ Bon sur Lobular (60.0% recall)
- ‚úÖ Compl√©mentarit√© CNN+ViT : features locales + contexte global
### Faiblesses

- ‚ùå Fibroadenoma : recall tr√®s faible (13.5% - r√©gression vs CNN 52%)
- ‚ö†Ô∏è Confusion Fibroadenoma ‚Üí Phyllodes (14 cas, 38%)
- ‚ö†Ô∏è Mucinous ‚Üí Ductal (11 cas confondus)
- ‚ö†Ô∏è L√©g√®rement d√©s√©quilibr√© vers Ductal (49% des pr√©dictions)
- ‚ö†Ô∏è Plus lourd que CNN (8.7M vs 4.4M param√®tres)
- ‚ö†Ô∏è Plus lent √† l'inf√©rence (~60ms vs ~2s par batch)
### Innovation Cl√© : R√©solution du Probl√®me Mucinous

Le Mucinous Carcinoma √©tait la classe la plus difficile pour tous les mod√®les. L'hybride am√©liore spectaculairement sa d√©tection :

Cette am√©lioration d√©montre la compl√©mentarit√© des features CNN (textures mucineuses) et ViT (organisation cellulaire) pour cette classe difficile.

### Verdict

Le mod√®le Hybride est le GAGNANT CLAIR de cette comparaison. Avec 64.36% d'accuracy et 75.57% de recall malignant, il surpasse significativement les approches pures. L'am√©lioration spectaculaire sur Mucinous Carcinoma (√ó5) et le recall malignant √©lev√© en font le candidat optimal pour l'assistance au diagnostic clinique. Cependant, le probl√®me de Fibroadenoma n√©cessite une attention particuli√®re (possiblement via weighted loss ou augmentation cibl√©e).


# 6. Comparaison D√©taill√©e

## 6.1 Performance Globale

* Recall malignant ViT trompeur : d√©tecte seulement 1 type de cancer sur 4

### Observations Cl√©s

- ‚Ä¢ L'Hybride domine sur toutes les m√©triques sauf l'√©quilibre
- ‚Ä¢ Le CNN est le plus √©quilibr√© mais avec performances modestes
- ‚Ä¢ Le ViT a totalement √©chou√© √† apprendre la diversit√© des classes
- ‚Ä¢ L'√©cart Hybride-CNN est significatif (+9.4% accuracy, +20.3% recall malin)
- ‚Ä¢ Le ViT ne devrait jamais √™tre utilis√© from scratch sur petits datasets

## 6.2 Analyse par Classe

Comparaison du recall par classe (capacit√© de d√©tection):

### Score par Mod√®le

Nombre de classes o√π le mod√®le obtient le meilleur recall :

‚Ä¢ ü•á Hybride : 4 victoires (Adenosis, Lobular, Mucinous + co-vainqueur Tubular)

‚Ä¢ ü•à CNN : 3 victoires (Fibroadenoma, Phyllodes, Papillary)

‚Ä¢ ü•â ViT : 2 victoires (Tubular, Ductal) - mais inutilisable globalement

### Classes Critiques (Cancers)

Focus sur les 4 types de cancer :

1. Ductal Carcinoma (896 √©chantillons - 69% des cancers)

‚Üí ViT excellent (90.8%) mais pr√©dit presque uniquement cette classe

‚Üí Hybride tr√®s bon (87.4%) avec d√©tection √©quilibr√©e


2. Lobular Carcinoma (163 √©chantillons)

‚Üí Hybride meilleur (60.0% vs CNN 53.3%)

‚Üí ViT totalement aveugle (0%) - confond tout avec Ductal


3. Mucinous Carcinoma (196 √©chantillons) - CLASSE LA PLUS DIFFICILE

‚Üí Hybride EXCELLENT (35.3%) - am√©lioration √ó5 vs CNN

‚Üí CNN catastrophique (6.7%)

‚Üí ViT aveugle (0%)


4. Papillary Carcinoma (135 √©chantillons)

‚Üí CNN l√©g√®rement meilleur (68.4% vs 66.7%)

‚Üí ViT aveugle (0%)


## 6.3 Matrices de Confusion

Les matrices de confusion r√©v√®lent les patterns d'erreurs de chaque mod√®le. Elles sont essentielles pour comprendre les confusions sp√©cifiques et identifier les paires de classes probl√©matiques.

### Matrice de Confusion - EfficientNet (CNN)

Le CNN pr√©sente une matrice relativement √©quilibr√©e avec des pr√©dictions distribu√©es sur toutes les classes. Probl√®me majeur : Mucinous confondu avec Adenosis (5 cas - cancer class√© comme b√©nin).

Confusions principales CNN :

- ‚Ä¢ Mucinous ‚Üí Adenosis : 5 cas (33% des Mucinous) - GRAVE
- ‚Ä¢ Ductal ‚Üí Papillary : 11 cas (confusion entre sous-types de carcinome)
- ‚Ä¢ Fibroadenoma ‚Üí Phyllodes : 6 cas (tumeurs b√©nignes similaires)
- ‚Ä¢ Ductal ‚Üí Lobular : 10 cas (sous-types malins)
### Matrice de Confusion - ViT

Le ViT pr√©sente une matrice EXTR√äMEMENT d√©s√©quilibr√©e. Deux colonnes dominent (Ductal 64%, Tubular 31%) tandis que 5 colonnes sont compl√®tement vides. C'est la signature d'un effondrement d'apprentissage.

Patterns ViT :

- ‚Ä¢ Pr√©dit 'Ductal' pour 64% de toutes les images
- ‚Ä¢ Pr√©dit 'Tubular' pour 31% de toutes les images
- ‚Ä¢ Ne pr√©dit JAMAIS : Adenosis, Fibroadenoma, Phyllodes, Mucinous, Papillary
- ‚Ä¢ Confond TOUS les cancers non-Ductal avec Ductal ou Tubular
- ‚Ä¢ Lobular Carcinoma : 15 cas, tous confondus avec Ductal (100% d'erreur)
### Matrice de Confusion - Hybride

L'Hybride pr√©sente une matrice plus √©quilibr√©e que le ViT, avec toutes les classes repr√©sent√©es. Cependant, un d√©s√©quilibre persiste vers Ductal (49% des pr√©dictions) et on observe une confusion majeure Fibroadenoma ‚Üí Phyllodes.

Confusions principales Hybride :

- ‚Ä¢ Fibroadenoma ‚Üí Phyllodes : 14 cas (38% des Fibroadenoma) - Principal probl√®me
- ‚Ä¢ Mucinous ‚Üí Ductal : 11 cas (65% des Mucinous non d√©tect√©s)
- ‚Ä¢ Ductal ‚Üí Papillary : 7 cas (confusion sous-types)
- ‚Ä¢ Lobular ‚Üí Ductal : 5 cas (33% des Lobular)
### Comparaison des Distributions de Pr√©dictions

La distribution des pr√©dictions r√©v√®le l'√©quilibre (ou d√©s√©quilibre) de chaque mod√®le :

Observation : Le CNN est le plus √©quilibr√© (toutes classes >3%), l'Hybride est biais√© vers Ductal (49%), et le ViT est compl√®tement d√©s√©quilibr√© (ne pr√©dit que 3 classes).


# 7. Insights et D√©couvertes

## 7.1 ViT from Scratch Inadapt√© aux Petits Datasets

L'√©chec spectaculaire du ViT from scratch confirme les observations de la litt√©rature : les Transformers n√©cessitent des datasets massifs (>100K images) ou un pr√©-entra√Ænement sur ImageNet-21k pour fonctionner correctement.

- ‚Ä¢ Manque d'inductive bias : contrairement aux CNN, les ViT n'ont pas de biais convolutif int√©gr√©
- ‚Ä¢ Dataset BreakHis trop petit : 1610 images d'entra√Ænement insuffisantes
- ‚Ä¢ Absence de pr√©-entra√Ænement : ViT from scratch n√©cessite >1M images
- ‚Ä¢ Convergence vers classe majoritaire : le mod√®le 'donne up' et pr√©dit Ductal
- ‚Ä¢ Learning rate inadapt√© : optimis√© pour fine-tuning, pas pour training from scratch
## 7.2 L'Hybride R√©sout le Probl√®me Mucinous

Le Mucinous Carcinoma est une classe particuli√®rement difficile avec des caract√©ristiques visuelles ambigu√´s (pr√©sence de mucus pouvant ressembler √† des espaces glandulaires b√©nins). L'hybride am√©liore spectaculairement sa d√©tection :

Hypoth√®se : La fusion CNN+ViT permet de combiner :

- ‚Ä¢ Features CNN : Textures mucineuses locales
- ‚Ä¢ Features ViT : Organisation cellulaire globale
- ‚Ä¢ R√©sultat : Meilleure discrimination Mucinous vs autres classes
## 7.3 Nouveau Probl√®me : Fibroadenoma

L'hybride introduit paradoxalement une nouvelle faiblesse : Fibroadenoma passe de 52% recall (CNN) √† seulement 13.5% recall (Hybride). Cette r√©gression est caus√©e par une confusion massive avec Phyllodes Tumor.

Analyse de la confusion Fibroadenoma ‚Üí Phyllodes :

- ‚Ä¢ 37 Fibroadenomas dans le test set
- ‚Ä¢ 5 correctement d√©tect√©s (13.5%)
- ‚Ä¢ 14 confondus avec Phyllodes (37.8%) - confusion principale
- ‚Ä¢ 6 confondus avec Tubular (16.2%)
- ‚Ä¢ 6 confondus avec Papillary (16.2%)
- ‚Ä¢ Les deux sont des tumeurs fibreuses b√©nignes avec morphologies similaires
Remarque : Le CNN avait le m√™me probl√®me (6 confusions Fibro‚ÜíPhyllodes) mais l'hybride l'amplifie significativement. Ceci sugg√®re que le ViT branch capture mal les diff√©rences subtiles entre tumeurs fibreuses.

## 7.4 Trade-off √âquilibre vs Performance

On observe un trade-off int√©ressant entre √©quilibre et performance absolue :

- ‚Ä¢ CNN : Tr√®s √©quilibr√© (entropie 2.73) mais performances modestes (55%)
- ‚Ä¢ Hybride : L√©g√®rement d√©s√©quilibr√© (entropie 2.36) mais meilleures performances (64%)
- ‚Ä¢ ViT : Tr√®s d√©s√©quilibr√© (entropie 1.17) ET mauvaises performances (45%)
Conclusion : Un l√©ger d√©s√©quilibre (vers la classe majoritaire Ductal) peut √™tre acceptable si les performances globales sont sup√©rieures et que toutes les classes restent d√©tectables.

## 7.5 Importance du Pr√©-entra√Ænement

La comparaison souligne l'importance critique du pr√©-entra√Ænement en imagerie m√©dicale avec petits datasets :

- ‚úÖ EfficientNet pr√©-entra√Æn√© (ImageNet) : 55% accuracy, 8/8 classes
- ‚úÖ Hybride avec CNN pr√©-entra√Æn√© : 64% accuracy, 8/8 classes
- ‚ùå ViT from scratch : 45% accuracy, 2/8 classes
La diff√©rence est massive : m√™me la branch ViT de l'hybride (non pr√©-entra√Æn√©e) fonctionne correctement gr√¢ce au guidage de la branch CNN pr√©-entra√Æn√©e.


# 8. Recommandations

## 8.1 Pour Usage Clinique Imm√©diat

Mod√®le Recommand√© : HYBRIDE CNN+ViT ü•á

Justifications :

- ‚úÖ Meilleure performance globale (64.36% accuracy)
- ‚úÖ Meilleur recall malignant (75.57%) - 99/131 cancers d√©tect√©s
- ‚úÖ D√©tecte toutes les 8 classes (aucune classe ignor√©e)
- ‚úÖ R√©sout le probl√®me Mucinous (am√©lioration √ó5)
- ‚úÖ Performances acceptables sur 7/8 classes
- ‚úÖ Architecture innovante avec compl√©mentarit√© CNN+ViT
Pr√©cautions d'Usage :

- ‚ö†Ô∏è Surveillance humaine obligatoire (recall 75% insuffisant pour autonomie)
- ‚ö†Ô∏è Attention particuli√®re aux Fibroadenoma (recall faible 13.5%)
- ‚ö†Ô∏è V√©rifier les pr√©dictions Phyllodes (possible Fibroadenoma)
- ‚ö†Ô∏è Ne pas utiliser comme outil de diagnostic unique
- ‚ö†Ô∏è Privil√©gier comme outil de triage/priorisation
## 8.2 Am√©liorations Prioritaires

1. R√©soudre le Probl√®me Fibroadenoma

- ‚Ä¢ Weighted loss : augmenter le poids de Fibroadenoma (√ó5)
- ‚Ä¢ Augmentation cibl√©e : plus d'augmentation pour Fibroadenoma
- ‚Ä¢ Attention mechanism : ajouter attention sur features discriminantes
- ‚Ä¢ Post-processing : si pr√©dit Phyllodes avec faible confiance, v√©rifier Fibroadenoma
2. Am√©liorer le Recall Malignant

- ‚Ä¢ Objectif : atteindre >90% recall malignant
- ‚Ä¢ Ensemble : combiner 3-5 mod√®les hybrides avec seeds diff√©rents
- ‚Ä¢ Calibration : ajuster seuils de d√©cision par classe
- ‚Ä¢ Rejection class : ajouter option 'incertain' pour revue humaine
3. Augmenter la R√©solution

- ‚Ä¢ Passer de 224√ó224 √† 384√ó384 pixels
- ‚Ä¢ Les ViT fonctionnent mieux avec r√©solutions √©lev√©es
- ‚Ä¢ Gain estim√© : +2-4% accuracy
4. Techniques d'Augmentation Avanc√©es

- ‚Ä¢ CutMix / MixUp pour r√©gularisation
- ‚Ä¢ AutoAugment pour politique d'augmentation optimale
- ‚Ä¢ Test-Time Augmentation (TTA) pour inf√©rence robuste
## 8.3 Pour la Recherche Future

Pistes d'Exploration :

1. ViT Pr√©-entra√Æn√© ImageNet-21k

‚Üí Tester ViT-B/16 pr√©-entra√Æn√© (gain estim√© +15-20%)


2. Architecture Swin Transformer

‚Üí Hi√©rarchie pyramidale + fen√™tres d'attention locale


3. Self-Supervised Pre-training

‚Üí Pr√©-entra√Æner sur l'ensemble du dataset BreakHis (7909 images)

‚Üí M√©thodes : SimCLR, MoCo, DINO


4. Cross-Attention CNN‚ÜîViT

‚Üí Remplacer la simple concatenation par cross-attention

‚Üí Permettre interaction dynamique entre branches


5. Multi-Scale Features

‚Üí Utiliser features √† plusieurs niveaux du CNN

‚Üí FPN (Feature Pyramid Network) + ViT


6. Foundation Models

‚Üí Fine-tuner des mod√®les massifs (EVA, SAM)

‚Üí Transfer learning depuis domaine m√©dical (PathologyFoundation)


7. Explainability

‚Üí Grad-CAM, attention maps, SHAP values

‚Üí Validation par pathologistes des r√©gions d'attention

## 8.4 Workflow Clinique Propos√©

Int√©gration du mod√®le hybride dans le workflow de pathologie :

1. ACQUISITION

‚Üí Num√©risation des lames histologiques (scanner)

‚Üí Extraction de patches 224√ó224 √† 200√ó de grossissement


2. PR√â-TRAITEMENT

‚Üí Normalisation des couleurs (Reinhard ou Macenko)

‚Üí Quality control (√©liminer patches flous/artefacts)


3. PR√âDICTION MOD√àLE

‚Üí Inf√©rence sur patches

‚Üí Agr√©gation des pr√©dictions par lame (vote majoritaire)

‚Üí Calcul des scores de confiance


4. TRIAGE AUTOMATIQUE

‚Üí Haute confiance B√©nin (>0.9) ‚Üí Priorit√© basse

‚Üí Toute pr√©diction Maligne ‚Üí Priorit√© HAUTE

‚Üí Faible confiance (<0.6) ‚Üí Revue humaine obligatoire


5. REVUE PAR PATHOLOGISTE

‚Üí Pathologiste examine cas prioritaires en premier

‚Üí Visualisation des attention maps pour guidance

‚Üí Validation/correction des pr√©dictions


6. FEEDBACK LOOP

‚Üí Corrections int√©gr√©es pour r√©-entra√Ænement

‚Üí Am√©lioration continue du mod√®le


# 9. Conclusions

## Synth√®se des R√©sultats

Cette √©tude comparative d√©montre la sup√©riorit√© de l'architecture Hybride CNN+ViT pour la classification d'images histopathologiques de cancer du sein. Avec 64.36% d'accuracy et 75.57% de recall malignant, l'hybride surpasse significativement les approches pures CNN (54.95%, 55.24%) ou ViT from scratch (44.55%, 60.31%*).

La compl√©mentarit√© CNN+ViT se manifeste particuli√®rement sur les classes difficiles : le Mucinous Carcinoma voit son recall multipli√© par 5 (35.3% vs 6.7%), d√©montrant la valeur ajout√©e de la fusion features locales + contexte global.

## D√©couvertes Majeures

1. ViT from scratch INADAPT√â aux petits datasets m√©dicaux

‚Üí Effondrement vers 2 classes, ignore 6 classes dont 3 cancers

‚Üí Pr√©-entra√Ænement ImageNet-21k absolument n√©cessaire


2. Fusion CNN+ViT r√©sout probl√®mes difficiles

‚Üí Mucinous Carcinoma : am√©lioration √ó5

‚Üí Synergie features texturales (CNN) + organisation spatiale (ViT)


3. Trade-off performance vs √©quilibre acceptable

‚Üí Hybride l√©g√®rement d√©s√©quilibr√© (49% Ductal) mais toutes classes OK

‚Üí Pr√©f√©rable √† CNN √©quilibr√© mais moins performant


4. Nouveau d√©fi : Fibroadenoma vs Phyllodes

‚Üí Confusion amplifi√©e par l'hybride (14 cas)

‚Üí N√©cessite attention particuli√®re (weighted loss)

## Implications Cliniques

Le mod√®le Hybride peut servir d'outil d'assistance au diagnostic avec les pr√©cautions suivantes :

- ‚úÖ ADAPT√â pour : Triage automatique, priorisation des cas
- ‚úÖ ADAPT√â pour : D√©tection de Ductal, Lobular, Papillary (recall >60%)
- ‚úÖ ADAPT√â pour : Am√©lioration du Mucinous (35% vs 7% baseline)
- ‚ö†Ô∏è PRUDENCE : Fibroadenoma (recall faible 13.5%)
- ‚ö†Ô∏è PRUDENCE : Recall global 76% - revue humaine obligatoire
- ‚ùå NON ADAPT√â : Diagnostic autonome sans supervision
- ‚ùå NON ADAPT√â : Remplacement du pathologiste
## Perspectives

Cette √©tude ouvre plusieurs perspectives prometteuses :

- ‚Ä¢ Court terme : D√©ploiement pilote dans service de pathologie
- ‚Ä¢ Moyen terme : ViT pr√©-entra√Æn√© + ensemble de mod√®les (objectif >85% recall malin)
- ‚Ä¢ Long terme : Foundation models sp√©cialis√©s en histopathologie
- ‚Ä¢ Validation externe : Tester sur datasets ind√©pendants (g√©n√©ralisation)
- ‚Ä¢ Collaboration clinique : √âtudes avec pathologistes pour validation
## Conclusion Finale

L'architecture Hybride CNN+ViT repr√©sente une avanc√©e significative pour la classification automatique d'images histopathologiques de cancer du sein. Ses performances sup√©rieures (64.36% accuracy, 75.57% recall malignant) et sa capacit√© √† r√©soudre des classes difficiles comme le Mucinous Carcinoma en font un candidat s√©rieux pour l'assistance au diagnostic clinique.

Cependant, les limitations identifi√©es (Fibroadenoma, recall 76%) soulignent que ce mod√®le doit √™tre consid√©r√© comme un outil d'ASSISTANCE, non de REMPLACEMENT du pathologiste. Le d√©veloppement futur devra se concentrer sur l'am√©lioration du recall malignant (objectif >90%) et la r√©solution du probl√®me Fibroadenoma pour atteindre un niveau de performance cliniquement robuste.

L'√©chec spectaculaire du ViT from scratch rappelle l'importance critique du pr√©-entra√Ænement en deep learning m√©dical. Cette le√ßon guidera les recherches futures vers l'exploitation de mod√®les pr√©-entra√Æn√©s et de foundation models sp√©cialis√©s.


# 10. Annexes

## 10.1 Configuration Exp√©rimentale

## 10.2 Temps d'Entra√Ænement

## 10.3 Hyperparam√®tres par Mod√®le

EfficientNet :

- ‚Ä¢ Layers frozen : 238 (backbone complet)
- ‚Ä¢ Layers trainable : Classification head uniquement
- ‚Ä¢ Dropout : 0.25
- ‚Ä¢ Learning rate : 1e-3 ‚Üí 1e-5 (fine-tune)
ViT :

- ‚Ä¢ Patch size : 16√ó16
- ‚Ä¢ Transformer blocks : 6
- ‚Ä¢ Attention heads : 12
- ‚Ä¢ MLP ratio : 2.0
- ‚Ä¢ Dropout : 0.3
- ‚Ä¢ Learning rate : 1e-4 ‚Üí 2.5e-6 (fine-tune)
Hybride :

- ‚Ä¢ CNN frozen : Oui (EfficientNetB0)
- ‚Ä¢ ViT blocks : 3 (r√©duit)
- ‚Ä¢ ViT heads : 6
- ‚Ä¢ Fusion dim : 1664 (1280 CNN + 384 ViT)
- ‚Ä¢ Dropout : 0.3 (ViT), 0.3 (head)
- ‚Ä¢ Learning rate : 1e-4 ‚Üí 5e-6 (fine-tune)
## 10.4 M√©triques Compl√®tes par Classe

Voir tableaux d√©taill√©s sections 6.2 et 6.3

## 10.5 R√©f√©rences

  1. Spanhol, F. A., et al. (2016). A Dataset for Breast Cancer Histopathological Image Classification. IEEE Transactions on Biomedical Engineering, 63(7), 1455-1462.

  2. Dosovitskiy, A., et al. (2021). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR 2021.

  3. Tan, M., & Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019.

  4. Liu, Z., et al. (2021). Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. ICCV 2021.

  5. Chen, R. J., et al. (2022). Towards a general-purpose foundation model for computational pathology. Nature Medicine, 28(6), 1132-1142.
## 10.6 Contact et Informations

Auteur : Lamia Ladraa
Date : 18 Janvier 2026
Projet : Classification BreakHis 8 classes
Repository : mammo-vision-research (GitHub)
Branch : 2-cnn-studies-multiclass

| Mod√®le | Accuracy | Recall Malin | Classes OK | Verdict |
|---|---|---|---|---|
| ü•á Hybride | 64.36% | 75.57% | 8/8 | RECOMMAND√â |
| ü•à EfficientNet | 54.95% | 55.24% | 8/8 | Baseline acceptable |
| ü•â ViT | 44.55% | 60.31%* | 2/8 | √âCHEC - Inutilisable |

| Caract√©ristique | Valeur |
|---|---|
| Total d'images | 2013 |
| Patients uniques | 81 |
| Classes | 8 (4 b√©nignes + 4 malignes) |
| R√©solution | 224√ó224 pixels (redimensionn√©) |
| Train set | 1610 images (80%) |
| Validation set | 201 images (10%) |
| Test set | 202 images (10%) |

| Composant | D√©tails |
|---|---|
| Backbone | EfficientNetB0 (pr√©-entra√Æn√© ImageNet) |
| Param√®tres totaux | 4.38M (329K entra√Ænables) |
| Features extraites | 1280 dimensions |
| Classification head | Dense(256) + Dropout(0.25) + Dense(8) |
| Activation finale | Softmax |

| M√©trique | Valeur | Interpr√©tation |
|---|---|---|
| Accuracy | 54.95% | Modeste mais honn√™te |
| Macro Recall | 51.59% | Performance √©quilibr√©e |
| Recall Malignant | 55.24% | 79/143 cancers d√©tect√©s |
| Classes d√©tect√©es | 8/8 | ‚úÖ Toutes les classes fonctionnent |
| Entropie | 2.73/3.0 | ‚úÖ Pr√©dictions bien √©quilibr√©es |

| Composant | D√©tails |
|---|---|
| Patch size | 16√ó16 pixels |
| Nombre de patches | 196 (14√ó14 patches) |
| Transformer blocks | 6 blocks |
| Attention heads | 12 t√™tes par block |
| Projection dim | 768 dimensions |
| Param√®tres totaux | ~21M (tous entra√Ænables) |
| Pr√©-entra√Ænement | ‚ùå AUCUN (from scratch) |

| M√©trique | Valeur | Interpr√©tation |
|---|---|---|
| Accuracy | 44.55% | ‚ùå √âchec total |
| Macro Recall | 21.93% | ‚ùå Tr√®s faible |
| Recall Malignant | 60.31% | ‚ö†Ô∏è Trompeur (voir analyse) |
| Classes d√©tect√©es | 2/8 | ‚ùå 6 classes ignor√©es |
| Entropie | 1.17/3.0 | ‚ùå Tr√®s d√©s√©quilibr√© |

| M√©trique | Valeur | Interpr√©tation |
|---|---|---|
| Accuracy | 64.36% | ü•á Meilleure performance |
| Macro Recall | 62.06% | ü•á +10.5% vs CNN |
| Recall Malignant | 75.57% | ü•á 99/131 cancers d√©tect√©s |
| Classes d√©tect√©es | 8/8 | ‚úÖ Toutes les classes |
| Entropie | 2.36/3.0 | ‚ö†Ô∏è L√©g√®rement biais√© (Ductal) |

| Mod√®le | Recall Mucinous | Am√©lioration |
|---|---|---|
| CNN | 6.7% (1/15) | Baseline |
| ViT | 0.0% (0/17) | - |
| Hybride | 35.3% (6/17) | √ó5.3 vs CNN |

| M√©trique | Hybride | CNN | ViT | Meilleur |
|---|---|---|---|---|
| Accuracy | 64.36% | 54.95% | 44.55% | Hybride |
| Macro Recall | 62.06% | 51.59% | 21.93% | Hybride |
| Recall Malignant | 75.57% | 55.24% | 60.31%* | Hybride |
| Precision (moy) | ~62% | ~44% | ~10% | Hybride |
| Classes d√©tect√©es | 8/8 | 8/8 | 2/8 | Hybride/CNN |
| Entropie | 2.36 | 2.73 | 1.17 | CNN |

| Classe | Type | Hybride | CNN | ViT | üèÜ |
|---|---|---|---|---|---|
| Adenosis | B√©nin | 87.5% | 58.3% | 0.0% | Hybride |
| Fibroadenoma | B√©nin | 13.5% | 52.0% | 0.0% | CNN |
| Tubular Adenoma | B√©nin | 76.9% | 33.3% | 84.6% | ViT |
| Phyllodes | B√©nin | 69.2% | 80.0% | 0.0% | CNN |
| Ductal | Malin | 87.4% | 60.6% | 90.8% | ViT |
| Lobular | Malin | 60.0% | 53.3% | 0.0% | Hybride |
| Mucinous | Malin | 35.3% | 6.7% | 0.0% | Hybride |
| Papillary | Malin | 66.7% | 68.4% | 0.0% | CNN |

| Classe | Hybride | CNN | ViT |
|---|---|---|---|
| Adenosis | 5.4% | 9.9% | 0.0% |
| Fibroadenoma | 3.5% | 7.9% | 0.0% |
| Tubular | 8.9% | 7.4% | 30.7% |
| Phyllodes | 11.9% | 13.9% | 0.0% |
| Ductal | 49.0% | 32.2% | 63.9% |
| Lobular | 6.4% | 9.9% | 5.4% |
| Mucinous | 3.5% | 3.5% | 0.0% |
| Papillary | 11.4% | 15.3% | 0.0% |

| Mod√®le | Recall | Faux N√©gatifs | Principale Confusion |
|---|---|---|---|
| CNN | 6.7% | 14/15 | Adenosis (5 cas) |
| ViT | 0.0% | 17/17 | Ductal (13 cas) |
| Hybride | 35.3% | 11/17 | Ductal (11 cas) |

| Param√®tre | Valeur |
|---|---|
| Plateforme | Google Colab (Tesla T4 GPU) |
| Framework | TensorFlow 2.19 / Keras 3 |
| Python | 3.12 |
| R√©solution images | 224√ó224 pixels |
| Batch size | 16-32 (selon mod√®le) |
| Optimizer | Adam |
| Learning rate initiale | 1e-3 √† 1e-4 |
| Fine-tune LR | 1e-5 √† 5e-6 |
| Epochs (initial) | 10-15 |
| Epochs (fine-tune) | 10 |
| Callbacks | EarlyStopping, ReduceLROnPlateau |
| Augmentation | Rotation, flip, zoom, translation |

| Mod√®le | Initial Training | Fine-tuning | Total | Temps/Epoch |
|---|---|---|---|---|
| EfficientNet | ~30 min | ~20 min | ~50 min | ~2 min |
| ViT | ~37 min | ~23 min | ~60 min | ~2.5 min |
| Hybride | ~30 min | ~30 min | ~60 min | ~3 min |

